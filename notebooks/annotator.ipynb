{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autodistill\n",
      "  Downloading autodistill-0.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting autodistill-grounded-sam\n",
      "  Downloading autodistill_grounded_sam-0.1.1-py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: supervision==0.9.0 in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from supervision==0.9.0) (1.24.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from supervision==0.9.0) (6.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from supervision==0.9.0) (4.7.0.72)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from supervision==0.9.0) (3.7.1)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from autodistill) (9.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autodistill) (4.65.0)\n",
      "Collecting rf-groundingdino\n",
      "  Downloading rf_groundingdino-0.1.2.tar.gz (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.4/82.4 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rf-segment-anything\n",
      "  Downloading rf_segment_anything-1.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from autodistill-grounded-sam) (2.0.1+cu118)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.9.0) (23.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.9.0) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.9.0) (4.40.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.9.0) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.9.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.9.0) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.9.0) (1.0.7)\n",
      "Collecting addict\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting timm\n",
      "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from rf-groundingdino->autodistill-grounded-sam) (0.15.2+cu118)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting yapf\n",
      "  Downloading yapf-0.40.0-py3-none-any.whl (250 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (2.0.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (4.4.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (3.9.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->autodistill-grounded-sam) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->autodistill-grounded-sam) (15.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->supervision==0.9.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->autodistill-grounded-sam) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->autodistill-grounded-sam) (1.2.1)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->rf-groundingdino->autodistill-grounded-sam) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.4/770.4 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->rf-groundingdino->autodistill-grounded-sam) (3.5.3)\n",
      "Collecting importlib-metadata>=6.6.0\n",
      "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
      "Collecting tomli>=2.0.1\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->rf-groundingdino->autodistill-grounded-sam) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->rf-groundingdino->autodistill-grounded-sam) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->rf-groundingdino->autodistill-grounded-sam) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->rf-groundingdino->autodistill-grounded-sam) (2.1.1)\n",
      "Building wheels for collected packages: rf-groundingdino, pycocotools\n",
      "  Building wheel for rf-groundingdino (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rf-groundingdino: filename=rf_groundingdino-0.1.2-py2.py3-none-any.whl size=88753 sha256=3f6ccbba76311c68d7daa27fa66ac92378b22b6d5adf0b233de53a6fdca3b1e6\n",
      "  Stored in directory: /root/.cache/pip/wheels/d6/3f/f8/137b4305e941ad2e0b66cba52e914dda7560308eb91e7e5e47\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl size=333292 sha256=962ceb4ce5d95bd4c428c5757f826d3ca6c8e6eba6c290a852e987de74d1d672\n",
      "  Stored in directory: /root/.cache/pip/wheels/58/e6/f9/f87c8f8be098b51b616871315318329cae12cdb618f4caac93\n",
      "Successfully built rf-groundingdino pycocotools\n",
      "Installing collected packages: tokenizers, safetensors, rf-segment-anything, addict, zipp, tomli, regex, fsspec, importlib-metadata, huggingface-hub, yapf, transformers, pycocotools, autodistill, timm, rf-groundingdino, autodistill-grounded-sam\n",
      "Successfully installed addict-2.4.0 autodistill-0.1.2 autodistill-grounded-sam-0.1.1 fsspec-2023.6.0 huggingface-hub-0.15.1 importlib-metadata-6.6.0 pycocotools-2.0.6 regex-2023.6.3 rf-groundingdino-0.1.2 rf-segment-anything-1.0 safetensors-0.3.1 timm-0.9.2 tokenizers-0.13.3 tomli-2.0.1 transformers-4.30.1 yapf-0.40.0 zipp-3.15.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install autodistill \\\n",
    "autodistill-grounded-sam \\\n",
    "supervision==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.0.6)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (6.23.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.14.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (8.2.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (23.1)\n",
      "Requirement already satisfied: pyzmq>=20 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.5.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n",
      "Tue Jun 13 16:39:32 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.02    Driver Version: 526.98       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:07:00.0  On |                  N/A |\n",
      "|  0%   45C    P5    19W / 200W |   1269MiB /  8192MiB |     32%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A        19      G   /Xwayland                       N/A      |\n",
      "|    0   N/A  N/A        20      G   /Xwayland                       N/A      |\n",
      "|    0   N/A  N/A        31      G   /Xwayland                       N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to load grounding dino directly\n",
      "downloading dino model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de30b79669be40a6be18987fc0c101d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd491a2bd2fb4543b6520115c66eb271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d67564e42d4e4d93c2790368d95978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921cd4e115d54975addb679982589451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa6bd995fdb424cb3f69efb252aa62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from autodistill.detection import CaptionOntology\n",
    "from autodistill_grounded_sam import GroundedSAM\n",
    "\n",
    "\n",
    "ontology=CaptionOntology({\n",
    "    \"white curb\": \"white_curb\",\n",
    "    \"red curb\": \"red_curb\",\n",
    "    \"helmet\":\"helmet\",\n",
    "    \"motorcycle wheel\":\"wheel\",\n",
    "    \"motorbike\":\"moto\",\n",
    "    \"motocycle\":\"moto\",\n",
    "    \"road\":\"road\"\n",
    "})\n",
    "base_model = GroundedSAM(ontology=ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitignore', '.vscode', '2019_americasGP', 'annotator.ipynb', 'compose-dev.yaml', 'dataset', 'docker-compose.yml', 'Dockerfile', 'helpers.py', 'live_inference.py', 'models', 'requirements.txt', 'video', 'yolo_inference.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['curb', 'curb', 'helmet', 'wheel', 'moto', 'moto', 'rider', 'road']\n",
      "1397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3119/2208928599.py:27: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for im in tqdm(imgs[300:301]):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cb26452d814467a8ed4843238c6983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/2019_americasGP/2019_AmericasGP_1268.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 8.00 GiB total capacity; 5.24 GiB already allocated; 0 bytes free; 6.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mprint\u001b[39m(im_path)\n\u001b[1;32m     30\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(im_path)\n\u001b[0;32m---> 32\u001b[0m detections \u001b[39m=\u001b[39m base_model\u001b[39m.\u001b[39;49mpredict(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mim_path)\n\u001b[1;32m     33\u001b[0m \u001b[39m#print(detections)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m box_annotator \u001b[39m=\u001b[39m sv\u001b[39m.\u001b[39mBoxAnnotator()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/autodistill_grounded_sam/grounded_sam.py:67\u001b[0m, in \u001b[0;36mGroundedSAM.predict\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m# SAM Predictions\u001b[39;00m\n\u001b[1;32m     65\u001b[0m xyxy \u001b[39m=\u001b[39m detections\u001b[39m.\u001b[39mxyxy\n\u001b[0;32m---> 67\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msam_predictor\u001b[39m.\u001b[39;49mset_image(image)\n\u001b[1;32m     68\u001b[0m result_masks \u001b[39m=\u001b[39m []\n\u001b[1;32m     69\u001b[0m \u001b[39mfor\u001b[39;00m box \u001b[39min\u001b[39;00m xyxy:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/predictor.py:60\u001b[0m, in \u001b[0;36mSamPredictor.set_image\u001b[0;34m(self, image, image_format)\u001b[0m\n\u001b[1;32m     57\u001b[0m input_image_torch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(input_image, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     58\u001b[0m input_image_torch \u001b[39m=\u001b[39m input_image_torch\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()[\u001b[39mNone\u001b[39;00m, :, :, :]\n\u001b[0;32m---> 60\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_torch_image(input_image_torch, image\u001b[39m.\u001b[39;49mshape[:\u001b[39m2\u001b[39;49m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/predictor.py:89\u001b[0m, in \u001b[0;36mSamPredictor.set_torch_image\u001b[0;34m(self, transformed_image, original_image_size)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(transformed_image\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:])\n\u001b[1;32m     88\u001b[0m input_image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpreprocess(transformed_image)\n\u001b[0;32m---> 89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mimage_encoder(input_image)\n\u001b[1;32m     90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_image_set \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/modeling/image_encoder.py:112\u001b[0m, in \u001b[0;36mImageEncoderViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_embed\n\u001b[1;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m--> 112\u001b[0m     x \u001b[39m=\u001b[39m blk(x)\n\u001b[1;32m    114\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneck(x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[1;32m    116\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/modeling/image_encoder.py:174\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    171\u001b[0m     H, W \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], x\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]\n\u001b[1;32m    172\u001b[0m     x, pad_hw \u001b[39m=\u001b[39m window_partition(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size)\n\u001b[0;32m--> 174\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(x)\n\u001b[1;32m    175\u001b[0m \u001b[39m# Reverse window partition\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/modeling/image_encoder.py:234\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    231\u001b[0m attn \u001b[39m=\u001b[39m (q \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale) \u001b[39m@\u001b[39m k\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_rel_pos:\n\u001b[0;32m--> 234\u001b[0m     attn \u001b[39m=\u001b[39m add_decomposed_rel_pos(attn, q, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrel_pos_h, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrel_pos_w, (H, W), (H, W))\n\u001b[1;32m    236\u001b[0m attn \u001b[39m=\u001b[39m attn\u001b[39m.\u001b[39msoftmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    237\u001b[0m x \u001b[39m=\u001b[39m (attn \u001b[39m@\u001b[39m v)\u001b[39m.\u001b[39mview(B, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, H, W, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m)\u001b[39m.\u001b[39mreshape(B, H, W, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/modeling/image_encoder.py:358\u001b[0m, in \u001b[0;36madd_decomposed_rel_pos\u001b[0;34m(attn, q, rel_pos_h, rel_pos_w, q_size, k_size)\u001b[0m\n\u001b[1;32m    354\u001b[0m rel_h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mbhwc,hkc->bhwk\u001b[39m\u001b[39m\"\u001b[39m, r_q, Rh)\n\u001b[1;32m    355\u001b[0m rel_w \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mbhwc,wkc->bhwk\u001b[39m\u001b[39m\"\u001b[39m, r_q, Rw)\n\u001b[1;32m    357\u001b[0m attn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 358\u001b[0m     attn\u001b[39m.\u001b[39;49mview(B, q_h, q_w, k_h, k_w) \u001b[39m+\u001b[39;49m rel_h[:, :, :, :, \u001b[39mNone\u001b[39;49;00m] \u001b[39m+\u001b[39;49m rel_w[:, :, :, \u001b[39mNone\u001b[39;49;00m, :]\n\u001b[1;32m    359\u001b[0m )\u001b[39m.\u001b[39mview(B, q_h \u001b[39m*\u001b[39m q_w, k_h \u001b[39m*\u001b[39m k_w)\n\u001b[1;32m    361\u001b[0m \u001b[39mreturn\u001b[39;00m attn\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 8.00 GiB total capacity; 5.24 GiB already allocated; 0 bytes free; 6.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "SOURCE_IMAGE_PATH=\"./2019_americasGP/\"\n",
    "ontology=CaptionOntology({\n",
    "    \"white curb\": \"curb\",\n",
    "    \"red curb\": \"curb\",\n",
    "    \"helmet\":\"helmet\",\n",
    "    \"wheel\":\"wheel\",\n",
    "    \"motorbike\":\"moto\",\n",
    "    \"motocycle\":\"moto\",\n",
    "    \"motorcycle rider\":\"rider\",\n",
    "    \"road\":\"road\"\n",
    "})\n",
    "\n",
    "classes=ontology.classes()\n",
    "print(classes)\n",
    "base_model.ontology=ontology\n",
    "base_model.box_threshold = 0.4\n",
    "base_model.text_threshold = 0.5\n",
    "\n",
    "imgs = sv.list_files_with_extensions(directory=SOURCE_IMAGE_PATH)\n",
    "\n",
    "print(len(imgs))\n",
    "\n",
    "for im in tqdm(imgs[300:301]):\n",
    "  im_path=str(im.absolute())\n",
    "  print(im_path)\n",
    "  image = cv2.imread(im_path)\n",
    "\n",
    "  detections = base_model.predict(input=im_path)\n",
    "  #print(detections)\n",
    "  \n",
    " \n",
    "  box_annotator = sv.BoxAnnotator()\n",
    "  mask_annotator = sv.MaskAnnotator()\n",
    "  annotated_frame = box_annotator.annotate(scene=image.copy(), detections=detections,labels=[classes[cls_id] for cls_id in detections.class_id])\n",
    "  image = mask_annotator.annotate(scene=annotated_frame, detections=detections,opacity=0.8)\n",
    "  h, w, c = image.shape\n",
    "  #image = image[0:h, 220:w]\n",
    "  sv.plot_image(image, (16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH=\"/home/jovyan/work/models/yolov8n-seg-150e.pt\"\n",
    "INPUT=SOURCE_IMAGE_PATH+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%yolo predict model={TRAINED_MODEL_PATH} source={INPUT_VIDEO_PATH}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
